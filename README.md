# Imagen Apex

<div align="center">

![Imagen Apex Banner](assets/hero_banner.png)

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Google Cloud](https://img.shields.io/badge/Google%20Cloud-Vertex%20AI-4285F4?logo=google-cloud)](https://cloud.google.com/vertex-ai)
[![YouTube Demo](https://img.shields.io/badge/YouTube-Demo-red?logo=youtube)](https://youtu.be/LmJgkbapeJQ)

**Transform text into stunning 3D models using cutting-edge AI**

[Quick Start](#-quick-start) â€¢ [Features](#-features) â€¢ [Architecture](#-architecture) â€¢ [Examples](#-examples) â€¢ [Deployment](#-deployment)

â–¶ï¸ **[Watch Demo on YouTube](https://youtu.be/LmJgkbapeJQ)**

</div>

---

## âœ¨ Features

- ğŸ¨ **Nano Banana Pro** - Google's state-of-the-art image generation (Gemini-powered)
- ğŸ”® **SAM 3D Objects** - Meta's breakthrough image-to-3D reconstruction
- âš¡ **End-to-End Pipeline** - Text prompt â†’ Generated Image â†’ 3D Model in one command
- ğŸš€ **Cloud-Ready** - Deploy on Vertex AI or Cloud Run with GPU support
- ğŸ”’ **Secure API** - Built-in API key authentication
- ğŸ“¦ **Multiple Formats** - Export to PLY, GLB for use in Blender, Unity, etc.

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Google Cloud account with billing enabled
- [HuggingFace account](https://huggingface.co) with access to [SAM 3D Objects](https://huggingface.co/facebook/sam-3d-objects)

### Installation

```bash
# Clone the repository
git clone https://github.com/lukehamond1001-alt/imagen-apex.git
cd imagen-apex

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your credentials
```

### Generate Your First 3D Model

```bash
# Text to 3D in one command
python -m src.pipeline --prompt "a red sports car" --output output/car.ply
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Text Prompt   â”‚ â”€â”€â–¶ â”‚ Nano Banana Pro â”‚ â”€â”€â–¶ â”‚    Generated    â”‚
â”‚                 â”‚     â”‚   (Vertex AI)   â”‚     â”‚      Image      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    3D Model     â”‚ â—€â”€â”€ â”‚   SAM 3D API    â”‚ â—€â”€â”€ â”‚  Image + Mask   â”‚
â”‚   (PLY/GLB)     â”‚     â”‚ (Cloud Run/GPU) â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline Flow

1. **Text Prompt** â†’ User provides a description (e.g., "a wooden chair")
2. **Image Generation** â†’ Nano Banana Pro creates a photorealistic image
3. **Object Masking** â†’ Automatic segmentation of the main object
4. **3D Reconstruction** â†’ SAM 3D converts the masked image to a 3D model
5. **Export** â†’ Save as PLY or GLB for visualization/editing

---

## ğŸ“¸ Examples

### Basic Usage

```python
from src.pipeline import TextTo3DPipeline

# Initialize the pipeline
pipeline = TextTo3DPipeline(
    project_id="your-gcp-project",
    sam3d_endpoint="https://your-sam3d-endpoint"
)

# Generate 3D model from text
result = pipeline.generate(
    prompt="a vintage wooden treasure chest",
    output_path="output/chest.ply"
)

print(f"âœ… 3D model saved: {result['ply']}")
print(f"ğŸ“· Source image: {result['image']}")
```

### Command Line

```bash
# Generate from text prompt
python -m src.pipeline --prompt "a ceramic coffee mug" --output mug.ply

# Use an existing image
python -m src.pipeline --image my_photo.jpg --output model.ply

# Image generation only
python -m src.image_generator --prompt "a golden crown" --output crown.png
```

---

## ğŸš¢ Deployment

### Option 1: Cloud Run with GPU (Recommended)

```bash
# Deploy SAM 3D server to Cloud Run
python deploy/deploy_cloudrun.py \
    --project your-project-id \
    --region us-central1 \
    --hf-token $HF_TOKEN
```

### Option 2: Vertex AI Endpoint

```bash
# Deploy to Vertex AI
python deploy/deploy_vertex.py \
    --project your-project-id \
    --region asia-east1 \
    --hf-token $HF_TOKEN
```

### Option 3: Local with Docker

```bash
# Build and run locally
cd server
docker build -t imagen-apex-sam3d --build-arg HF_TOKEN=$HF_TOKEN .
docker run --gpus all -p 8080:8080 imagen-apex-sam3d
```

---

## ğŸ’° Cost Estimation

| Resource | Cost |
|----------|------|
| Nano Banana Pro (Image Generation) | ~$0.04/image |
| Cloud Run GPU (L4) | ~$0.75/hour |
| Vertex AI GPU (V100) | ~$2.50/hour |
| Vertex AI GPU (A100 40GB) | ~$3.50/hour |

> ğŸ’¡ **Tip**: Use `python deploy/deploy_vertex.py --undeploy` to stop your endpoint when not in use.

---

## ğŸ“ Project Structure

```
imagen-apex/
â”œâ”€â”€ src/                    # Core pipeline code
â”‚   â”œâ”€â”€ pipeline.py         # Main orchestration
â”‚   â”œâ”€â”€ image_generator.py  # Nano Banana Pro client
â”‚   â”œâ”€â”€ sam3d_client.py     # SAM 3D API client
â”‚   â””â”€â”€ utils.py            # Helper functions
â”œâ”€â”€ server/                 # SAM 3D server container
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ handler.py
â”œâ”€â”€ frontend/               # React web interface
â”‚   â”œâ”€â”€ App.tsx             # Main React component
â”‚   â”œâ”€â”€ components/         # UI components
â”‚   â”œâ”€â”€ services/           # API integrations
â”‚   â””â”€â”€ README.md           # Frontend documentation
â”œâ”€â”€ deploy/                 # Deployment scripts
â”‚   â”œâ”€â”€ deploy_vertex.py
â”‚   â””â”€â”€ deploy_cloudrun.py
â”œâ”€â”€ examples/               # Usage examples
â””â”€â”€ docs/                   # Documentation
```

---

## ğŸ”§ Configuration

Create a `.env` file based on `.env.example`:

```bash
# Google Cloud
GCP_PROJECT_ID=your-project-id
GCP_REGION=us-central1

# SAM 3D Endpoint
SAM3D_ENDPOINT=https://your-endpoint-url
SAM3D_API_KEY=your-api-key

# HuggingFace (for model downloads)
HF_TOKEN=your-huggingface-token
```

---

## ğŸ› Troubleshooting

<details>
<summary><strong>"Endpoint not found"</strong></summary>

Deploy the SAM 3D server first:
```bash
python deploy/deploy_cloudrun.py --hf-token $HF_TOKEN
```
</details>

<details>
<summary><strong>"Model server never became ready"</strong></summary>

- Verify your HuggingFace token has access to [facebook/sam-3d-objects](https://huggingface.co/facebook/sam-3d-objects)
- Check your GPU quota in the GCP Console
</details>

<details>
<summary><strong>"CUDA out of memory"</strong></summary>

- Images are automatically resized to 256x256 for L4 GPUs
- Use a larger GPU (V100/A100) for higher resolution
</details>

---

## ğŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Google Cloud Vertex AI](https://cloud.google.com/vertex-ai) - Nano Banana Pro image generation
- [Meta Research](https://github.com/facebookresearch/sam-3d-objects) - SAM 3D Objects model
- [HuggingFace](https://huggingface.co) - Model hosting and distribution

---

<div align="center">
<strong>Made with â¤ï¸ by Luke Hamond</strong>
</div>
